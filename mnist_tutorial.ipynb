{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "WP5gHqgP_Zbw",
        "LTMcZztY_Zb0",
        "YlPd9a6q_ZcD",
        "JKmCf9xJ_ZcN",
        "UZU6FrgX_ZcT",
        "nn6eiB-f_ZcZ",
        "K9uwiVWV_Zcc",
        "c1Lr6sR3_Zct",
        "vOm7hZdy_Zcw",
        "do0f831X_Zc0",
        "oLfayLBK_Zc4",
        "edEHShhD_Zc9",
        "gdYC7vUP_ZdI",
        "Mc54ZB07_ZdQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsoroush/mnist_inception_finetune/blob/master/mnist_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "d95674766b31d56a076ec3495a871fe171348d3d",
        "id": "PRzhwcN__ZbA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a> <br>\n",
        "# Import Required Libraries\n",
        "\n",
        "As the first step, we need to import needed libraries"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "9BCYB78H_ZbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Input, UpSampling3D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1T9_BFN14kKU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load and Prepare Data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e66215d19f779dd26771a0da862c008bade3e34c",
        "id": "WsjpvKVv_ZbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "adb0dd99-b5d0-4269-a3bf-22b2f07c3a83"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print('X train: ', x_train.shape)\n",
        "print('y train: ', y_train.shape)\n",
        "print('X test: ', x_test.shape)\n",
        "print('y test: ', y_test.shape)\n",
        "\n",
        "x_train = (x_train / 255).astype('float32')\n",
        "x_test = (x_test / 255).astype('float32')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X train:  (60000, 28, 28)\n",
            "y train:  (60000,)\n",
            "X test:  (10000, 28, 28)\n",
            "y test:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "e9d8db3a00b23c965bda0834f41e7186e0b2939a",
        "id": "lthZcmkm_ZbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Input in in th shape 1 * 784 arrays. We convert them to an image of 28 * 28 pixel to be able to use convolutional layers.\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11f6ee7afe8e7b2291bb6f7bb4fa5a39c2629862",
        "id": "5T1GVrLM_ZbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1d4c084c-efd8-4b91-de27-fd6af2b9273c"
      },
      "cell_type": "code",
      "source": [
        "#expand 1 more dimention as 1 for colour channel gray\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "print(x_train.shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "6d9cee8f02c5b48e3461140d21828b173f13c1e4",
        "id": "TrSMVjk4_ZbW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have a number for each image but we need an array.\n",
        "2 has to be converted to [0, 0, 1, 0, 0 ,0 ,0 ,0 ,0 ,0] "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c517b899b9a7dd753d9c74a07c9ecdf2415a6c5",
        "id": "Y4pbBduy_ZbW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9e7a121-3acb-4dd9-e8da-267b8b6c2e8c"
      },
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "num_classes = y_train.shape[1]\n",
        "y_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "r7Wflh1e5BWU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split training set to train and validation sets:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a68e9dd05663f7f7f4c494c16c9faed10838e4e",
        "id": "jzHOleRg_Zbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "random_seed = 2\n",
        "# Split the train and the validation set for the fitting\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=random_seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4e4a77db18798635913836adce710355afdea1a2",
        "id": "rX-ikYKb_Zbs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"9\"></a> <br>\n",
        "# Define the Model"
      ]
    },
    {
      "metadata": {
        "id": "nXClhuIxuRd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "f99e4119-2ede-4e00-cbbb-2d50123c7bed"
      },
      "cell_type": "code",
      "source": [
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "input_inception = Input(shape=(28, 28, 1), dtype='float32', name='inception_input')\n",
        "\n",
        "# create the base pre-trained model\n",
        "x = UpSampling3D(size=(3, 3, 3), data_format=\"channels_last\")(input_inception)\n",
        "# x = Conv2D(filters=3, kernel_size=1, padding=\"same\", activation='relu', data_format='channels_last')(x)\n",
        "\n",
        "x = base_model(x)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "# x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "# and a logistic layer\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "inceptionv3_model = Model(inputs=input_inception, outputs=predictions)\n",
        "\n",
        "inceptionv3_model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_input (InputLayer) (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling3d_3 (UpSampling3 (None, 84, 84, 3)         0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Model)         multiple                  21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 23,911,210\n",
            "Trainable params: 23,876,778\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5nPDELRX5a-d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Freeze the First 2 Blocks"
      ]
    },
    {
      "metadata": {
        "id": "LDLEBNqbwCx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5491
        },
        "outputId": "d48321ac-6c0d-4493-b9be-de1dc63a3091"
      },
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_3\n",
            "1 conv2d_189\n",
            "2 batch_normalization_189\n",
            "3 activation_189\n",
            "4 conv2d_190\n",
            "5 batch_normalization_190\n",
            "6 activation_190\n",
            "7 conv2d_191\n",
            "8 batch_normalization_191\n",
            "9 activation_191\n",
            "10 max_pooling2d_9\n",
            "11 conv2d_192\n",
            "12 batch_normalization_192\n",
            "13 activation_192\n",
            "14 conv2d_193\n",
            "15 batch_normalization_193\n",
            "16 activation_193\n",
            "17 max_pooling2d_10\n",
            "18 conv2d_197\n",
            "19 batch_normalization_197\n",
            "20 activation_197\n",
            "21 conv2d_195\n",
            "22 conv2d_198\n",
            "23 batch_normalization_195\n",
            "24 batch_normalization_198\n",
            "25 activation_195\n",
            "26 activation_198\n",
            "27 average_pooling2d_19\n",
            "28 conv2d_194\n",
            "29 conv2d_196\n",
            "30 conv2d_199\n",
            "31 conv2d_200\n",
            "32 batch_normalization_194\n",
            "33 batch_normalization_196\n",
            "34 batch_normalization_199\n",
            "35 batch_normalization_200\n",
            "36 activation_194\n",
            "37 activation_196\n",
            "38 activation_199\n",
            "39 activation_200\n",
            "40 mixed0\n",
            "41 conv2d_204\n",
            "42 batch_normalization_204\n",
            "43 activation_204\n",
            "44 conv2d_202\n",
            "45 conv2d_205\n",
            "46 batch_normalization_202\n",
            "47 batch_normalization_205\n",
            "48 activation_202\n",
            "49 activation_205\n",
            "50 average_pooling2d_20\n",
            "51 conv2d_201\n",
            "52 conv2d_203\n",
            "53 conv2d_206\n",
            "54 conv2d_207\n",
            "55 batch_normalization_201\n",
            "56 batch_normalization_203\n",
            "57 batch_normalization_206\n",
            "58 batch_normalization_207\n",
            "59 activation_201\n",
            "60 activation_203\n",
            "61 activation_206\n",
            "62 activation_207\n",
            "63 mixed1\n",
            "64 conv2d_211\n",
            "65 batch_normalization_211\n",
            "66 activation_211\n",
            "67 conv2d_209\n",
            "68 conv2d_212\n",
            "69 batch_normalization_209\n",
            "70 batch_normalization_212\n",
            "71 activation_209\n",
            "72 activation_212\n",
            "73 average_pooling2d_21\n",
            "74 conv2d_208\n",
            "75 conv2d_210\n",
            "76 conv2d_213\n",
            "77 conv2d_214\n",
            "78 batch_normalization_208\n",
            "79 batch_normalization_210\n",
            "80 batch_normalization_213\n",
            "81 batch_normalization_214\n",
            "82 activation_208\n",
            "83 activation_210\n",
            "84 activation_213\n",
            "85 activation_214\n",
            "86 mixed2\n",
            "87 conv2d_216\n",
            "88 batch_normalization_216\n",
            "89 activation_216\n",
            "90 conv2d_217\n",
            "91 batch_normalization_217\n",
            "92 activation_217\n",
            "93 conv2d_215\n",
            "94 conv2d_218\n",
            "95 batch_normalization_215\n",
            "96 batch_normalization_218\n",
            "97 activation_215\n",
            "98 activation_218\n",
            "99 max_pooling2d_11\n",
            "100 mixed3\n",
            "101 conv2d_223\n",
            "102 batch_normalization_223\n",
            "103 activation_223\n",
            "104 conv2d_224\n",
            "105 batch_normalization_224\n",
            "106 activation_224\n",
            "107 conv2d_220\n",
            "108 conv2d_225\n",
            "109 batch_normalization_220\n",
            "110 batch_normalization_225\n",
            "111 activation_220\n",
            "112 activation_225\n",
            "113 conv2d_221\n",
            "114 conv2d_226\n",
            "115 batch_normalization_221\n",
            "116 batch_normalization_226\n",
            "117 activation_221\n",
            "118 activation_226\n",
            "119 average_pooling2d_22\n",
            "120 conv2d_219\n",
            "121 conv2d_222\n",
            "122 conv2d_227\n",
            "123 conv2d_228\n",
            "124 batch_normalization_219\n",
            "125 batch_normalization_222\n",
            "126 batch_normalization_227\n",
            "127 batch_normalization_228\n",
            "128 activation_219\n",
            "129 activation_222\n",
            "130 activation_227\n",
            "131 activation_228\n",
            "132 mixed4\n",
            "133 conv2d_233\n",
            "134 batch_normalization_233\n",
            "135 activation_233\n",
            "136 conv2d_234\n",
            "137 batch_normalization_234\n",
            "138 activation_234\n",
            "139 conv2d_230\n",
            "140 conv2d_235\n",
            "141 batch_normalization_230\n",
            "142 batch_normalization_235\n",
            "143 activation_230\n",
            "144 activation_235\n",
            "145 conv2d_231\n",
            "146 conv2d_236\n",
            "147 batch_normalization_231\n",
            "148 batch_normalization_236\n",
            "149 activation_231\n",
            "150 activation_236\n",
            "151 average_pooling2d_23\n",
            "152 conv2d_229\n",
            "153 conv2d_232\n",
            "154 conv2d_237\n",
            "155 conv2d_238\n",
            "156 batch_normalization_229\n",
            "157 batch_normalization_232\n",
            "158 batch_normalization_237\n",
            "159 batch_normalization_238\n",
            "160 activation_229\n",
            "161 activation_232\n",
            "162 activation_237\n",
            "163 activation_238\n",
            "164 mixed5\n",
            "165 conv2d_243\n",
            "166 batch_normalization_243\n",
            "167 activation_243\n",
            "168 conv2d_244\n",
            "169 batch_normalization_244\n",
            "170 activation_244\n",
            "171 conv2d_240\n",
            "172 conv2d_245\n",
            "173 batch_normalization_240\n",
            "174 batch_normalization_245\n",
            "175 activation_240\n",
            "176 activation_245\n",
            "177 conv2d_241\n",
            "178 conv2d_246\n",
            "179 batch_normalization_241\n",
            "180 batch_normalization_246\n",
            "181 activation_241\n",
            "182 activation_246\n",
            "183 average_pooling2d_24\n",
            "184 conv2d_239\n",
            "185 conv2d_242\n",
            "186 conv2d_247\n",
            "187 conv2d_248\n",
            "188 batch_normalization_239\n",
            "189 batch_normalization_242\n",
            "190 batch_normalization_247\n",
            "191 batch_normalization_248\n",
            "192 activation_239\n",
            "193 activation_242\n",
            "194 activation_247\n",
            "195 activation_248\n",
            "196 mixed6\n",
            "197 conv2d_253\n",
            "198 batch_normalization_253\n",
            "199 activation_253\n",
            "200 conv2d_254\n",
            "201 batch_normalization_254\n",
            "202 activation_254\n",
            "203 conv2d_250\n",
            "204 conv2d_255\n",
            "205 batch_normalization_250\n",
            "206 batch_normalization_255\n",
            "207 activation_250\n",
            "208 activation_255\n",
            "209 conv2d_251\n",
            "210 conv2d_256\n",
            "211 batch_normalization_251\n",
            "212 batch_normalization_256\n",
            "213 activation_251\n",
            "214 activation_256\n",
            "215 average_pooling2d_25\n",
            "216 conv2d_249\n",
            "217 conv2d_252\n",
            "218 conv2d_257\n",
            "219 conv2d_258\n",
            "220 batch_normalization_249\n",
            "221 batch_normalization_252\n",
            "222 batch_normalization_257\n",
            "223 batch_normalization_258\n",
            "224 activation_249\n",
            "225 activation_252\n",
            "226 activation_257\n",
            "227 activation_258\n",
            "228 mixed7\n",
            "229 conv2d_261\n",
            "230 batch_normalization_261\n",
            "231 activation_261\n",
            "232 conv2d_262\n",
            "233 batch_normalization_262\n",
            "234 activation_262\n",
            "235 conv2d_259\n",
            "236 conv2d_263\n",
            "237 batch_normalization_259\n",
            "238 batch_normalization_263\n",
            "239 activation_259\n",
            "240 activation_263\n",
            "241 conv2d_260\n",
            "242 conv2d_264\n",
            "243 batch_normalization_260\n",
            "244 batch_normalization_264\n",
            "245 activation_260\n",
            "246 activation_264\n",
            "247 max_pooling2d_12\n",
            "248 mixed8\n",
            "249 conv2d_269\n",
            "250 batch_normalization_269\n",
            "251 activation_269\n",
            "252 conv2d_266\n",
            "253 conv2d_270\n",
            "254 batch_normalization_266\n",
            "255 batch_normalization_270\n",
            "256 activation_266\n",
            "257 activation_270\n",
            "258 conv2d_267\n",
            "259 conv2d_268\n",
            "260 conv2d_271\n",
            "261 conv2d_272\n",
            "262 average_pooling2d_26\n",
            "263 conv2d_265\n",
            "264 batch_normalization_267\n",
            "265 batch_normalization_268\n",
            "266 batch_normalization_271\n",
            "267 batch_normalization_272\n",
            "268 conv2d_273\n",
            "269 batch_normalization_265\n",
            "270 activation_267\n",
            "271 activation_268\n",
            "272 activation_271\n",
            "273 activation_272\n",
            "274 batch_normalization_273\n",
            "275 activation_265\n",
            "276 mixed9_0\n",
            "277 concatenate_5\n",
            "278 activation_273\n",
            "279 mixed9\n",
            "280 conv2d_278\n",
            "281 batch_normalization_278\n",
            "282 activation_278\n",
            "283 conv2d_275\n",
            "284 conv2d_279\n",
            "285 batch_normalization_275\n",
            "286 batch_normalization_279\n",
            "287 activation_275\n",
            "288 activation_279\n",
            "289 conv2d_276\n",
            "290 conv2d_277\n",
            "291 conv2d_280\n",
            "292 conv2d_281\n",
            "293 average_pooling2d_27\n",
            "294 conv2d_274\n",
            "295 batch_normalization_276\n",
            "296 batch_normalization_277\n",
            "297 batch_normalization_280\n",
            "298 batch_normalization_281\n",
            "299 conv2d_282\n",
            "300 batch_normalization_274\n",
            "301 activation_276\n",
            "302 activation_277\n",
            "303 activation_280\n",
            "304 activation_281\n",
            "305 batch_normalization_282\n",
            "306 activation_274\n",
            "307 mixed9_1\n",
            "308 concatenate_6\n",
            "309 activation_282\n",
            "310 mixed10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pL7ajDMZxZnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "d461127a-6ac7-4153-8610-9a3b295d9beb"
      },
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:64]:\n",
        "   layer.trainable = False\n",
        "    \n",
        "inceptionv3_model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_input (InputLayer) (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling3d_3 (UpSampling3 (None, 84, 84, 3)         0         \n",
            "_________________________________________________________________\n",
            "inception_v3 (Model)         multiple                  21802784  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 23,911,210\n",
            "Trainable params: 23,172,090\n",
            "Non-trainable params: 739,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z_sJasku5k79",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compile and Fit the Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "750ecd8200b9017853fc6a6c5bb427a8ccbe84a9",
        "id": "digxBRpQ_ZcF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the optimizer\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2844cd3bf731b21d7163c0444a838c0756ee3c75",
        "id": "Chfs6D38_ZcH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.005, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95290d032cfc52c46010e92fe16ef7610262fc7c",
        "id": "Q_WOpn1g_Zcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inceptionv3_model.compile(optimizer=optimizer , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ef40fafc365a53f66e7b3f60944e6139246d43c",
        "id": "kAcl5JMs_Zcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "1fa259e5-e3cb-4d1d-f95d-37f216d883b2"
      },
      "cell_type": "code",
      "source": [
        "inceptionv3_history = inceptionv3_model.fit(x_train, y_train, epochs=20, batch_size=64,\n",
        "                                            validation_data=(x_val, y_val),\n",
        "                                            shuffle=True,\n",
        "                                            callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 224s 5ms/step - loss: 0.4239 - acc: 0.9119 - val_loss: 1.0341 - val_acc: 0.9090\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 199s 4ms/step - loss: 0.2916 - acc: 0.9680 - val_loss: 1.1052 - val_acc: 0.9209\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 199s 4ms/step - loss: 0.2489 - acc: 0.9732 - val_loss: 1.7698 - val_acc: 0.8823\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 193s 4ms/step - loss: 0.3403 - acc: 0.9701 - val_loss: 0.3789 - val_acc: 0.9671\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 192s 4ms/step - loss: 0.2848 - acc: 0.9746 - val_loss: 0.2784 - val_acc: 0.9764\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 192s 4ms/step - loss: 0.2935 - acc: 0.9763 - val_loss: 0.2274 - val_acc: 0.9796\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 194s 4ms/step - loss: 0.0910 - acc: 0.9889 - val_loss: 0.1075 - val_acc: 0.9868\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 201s 4ms/step - loss: 0.1453 - acc: 0.9857 - val_loss: 0.0508 - val_acc: 0.9922\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 199s 4ms/step - loss: 0.1371 - acc: 0.9871 - val_loss: 0.2927 - val_acc: 0.9764\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 198s 4ms/step - loss: 0.2805 - acc: 0.9787 - val_loss: 0.0838 - val_acc: 0.9905\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 193s 4ms/step - loss: 0.2254 - acc: 0.9824 - val_loss: 0.0492 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 193s 4ms/step - loss: 0.0320 - acc: 0.9955 - val_loss: 0.0554 - val_acc: 0.9925\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 193s 4ms/step - loss: 0.0221 - acc: 0.9970 - val_loss: 0.0534 - val_acc: 0.9930\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 202s 4ms/step - loss: 0.0231 - acc: 0.9971 - val_loss: 0.0527 - val_acc: 0.9931\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 198s 4ms/step - loss: 0.0219 - acc: 0.9974 - val_loss: 0.0528 - val_acc: 0.9932\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 197s 4ms/step - loss: 0.0170 - acc: 0.9979 - val_loss: 0.0535 - val_acc: 0.9933\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 193s 4ms/step - loss: 0.0206 - acc: 0.9977 - val_loss: 0.0544 - val_acc: 0.9933\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 193s 4ms/step - loss: 0.0181 - acc: 0.9980 - val_loss: 0.0558 - val_acc: 0.9934\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 197s 4ms/step - loss: 0.0186 - acc: 0.9980 - val_loss: 0.0555 - val_acc: 0.9935\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 195s 4ms/step - loss: 0.0177 - acc: 0.9980 - val_loss: 0.0569 - val_acc: 0.9935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tm3w0ygRmszj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}