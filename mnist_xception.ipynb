{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_xception.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsoroush/mnist_inception_finetune/blob/master/mnist_xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0EoSRcYrZtrt",
        "colab_type": "code",
        "outputId": "05f9484c-0c28-4c61-9f11-d82461d08aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Input, UpSampling3D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.applications.xception import Xception\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "7fUkq5hFacEA",
        "colab_type": "code",
        "outputId": "1e0d9e97-f7db-4bed-ba24-2a82deba8539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = (x_train / 255).astype('float32')\n",
        "x_test = (x_test / 255).astype('float32')\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "random_seed = 2\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=random_seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UEcxGvrTfHhD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "                             samplewise_center=False,  # set each sample mean to 0\n",
        "                             featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "                             samplewise_std_normalization=False,  # divide each input by its std\n",
        "                             zca_whitening=False,  # apply ZCA whitening\n",
        "                             rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "                             zoom_range = 0.1, # Randomly zoom image \n",
        "                             width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "                             height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "                             horizontal_flip=False,  # randomly flip images\n",
        "                             vertical_flip=False)  # randomly flip images)\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdEwKOrQa3d0",
        "colab_type": "code",
        "outputId": "c9fcb308-ef13-4643-a3a5-b2f4dca29fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "cell_type": "code",
      "source": [
        "# create the base pre-trained model\n",
        "base_model = Xception(weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "input_xception = Input(shape=(28, 28, 1), dtype='float32', name='xception_input')\n",
        "\n",
        "x = UpSampling3D(size=(3, 3, 3), data_format=\"channels_last\")(input_xception)\n",
        "x = base_model(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# and a logistic layer\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "xception_model = Model(inputs=input_xception, outputs=predictions)\n",
        "\n",
        "xception_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 3s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling3d_1 (UpSampling3 (None, 84, 84, 3)         0         \n",
            "_________________________________________________________________\n",
            "xception (Model)             multiple                  20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 22,969,906\n",
            "Trainable params: 22,915,378\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FxzBkVJKbWYy",
        "colab_type": "code",
        "outputId": "950606e6-c1fb-4e57-a6e7-29881bc7a328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2340
        }
      },
      "cell_type": "code",
      "source": [
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 block1_conv1\n",
            "2 block1_conv1_bn\n",
            "3 block1_conv1_act\n",
            "4 block1_conv2\n",
            "5 block1_conv2_bn\n",
            "6 block1_conv2_act\n",
            "7 block2_sepconv1\n",
            "8 block2_sepconv1_bn\n",
            "9 block2_sepconv2_act\n",
            "10 block2_sepconv2\n",
            "11 block2_sepconv2_bn\n",
            "12 conv2d_1\n",
            "13 block2_pool\n",
            "14 batch_normalization_1\n",
            "15 add_1\n",
            "16 block3_sepconv1_act\n",
            "17 block3_sepconv1\n",
            "18 block3_sepconv1_bn\n",
            "19 block3_sepconv2_act\n",
            "20 block3_sepconv2\n",
            "21 block3_sepconv2_bn\n",
            "22 conv2d_2\n",
            "23 block3_pool\n",
            "24 batch_normalization_2\n",
            "25 add_2\n",
            "26 block4_sepconv1_act\n",
            "27 block4_sepconv1\n",
            "28 block4_sepconv1_bn\n",
            "29 block4_sepconv2_act\n",
            "30 block4_sepconv2\n",
            "31 block4_sepconv2_bn\n",
            "32 conv2d_3\n",
            "33 block4_pool\n",
            "34 batch_normalization_3\n",
            "35 add_3\n",
            "36 block5_sepconv1_act\n",
            "37 block5_sepconv1\n",
            "38 block5_sepconv1_bn\n",
            "39 block5_sepconv2_act\n",
            "40 block5_sepconv2\n",
            "41 block5_sepconv2_bn\n",
            "42 block5_sepconv3_act\n",
            "43 block5_sepconv3\n",
            "44 block5_sepconv3_bn\n",
            "45 add_4\n",
            "46 block6_sepconv1_act\n",
            "47 block6_sepconv1\n",
            "48 block6_sepconv1_bn\n",
            "49 block6_sepconv2_act\n",
            "50 block6_sepconv2\n",
            "51 block6_sepconv2_bn\n",
            "52 block6_sepconv3_act\n",
            "53 block6_sepconv3\n",
            "54 block6_sepconv3_bn\n",
            "55 add_5\n",
            "56 block7_sepconv1_act\n",
            "57 block7_sepconv1\n",
            "58 block7_sepconv1_bn\n",
            "59 block7_sepconv2_act\n",
            "60 block7_sepconv2\n",
            "61 block7_sepconv2_bn\n",
            "62 block7_sepconv3_act\n",
            "63 block7_sepconv3\n",
            "64 block7_sepconv3_bn\n",
            "65 add_6\n",
            "66 block8_sepconv1_act\n",
            "67 block8_sepconv1\n",
            "68 block8_sepconv1_bn\n",
            "69 block8_sepconv2_act\n",
            "70 block8_sepconv2\n",
            "71 block8_sepconv2_bn\n",
            "72 block8_sepconv3_act\n",
            "73 block8_sepconv3\n",
            "74 block8_sepconv3_bn\n",
            "75 add_7\n",
            "76 block9_sepconv1_act\n",
            "77 block9_sepconv1\n",
            "78 block9_sepconv1_bn\n",
            "79 block9_sepconv2_act\n",
            "80 block9_sepconv2\n",
            "81 block9_sepconv2_bn\n",
            "82 block9_sepconv3_act\n",
            "83 block9_sepconv3\n",
            "84 block9_sepconv3_bn\n",
            "85 add_8\n",
            "86 block10_sepconv1_act\n",
            "87 block10_sepconv1\n",
            "88 block10_sepconv1_bn\n",
            "89 block10_sepconv2_act\n",
            "90 block10_sepconv2\n",
            "91 block10_sepconv2_bn\n",
            "92 block10_sepconv3_act\n",
            "93 block10_sepconv3\n",
            "94 block10_sepconv3_bn\n",
            "95 add_9\n",
            "96 block11_sepconv1_act\n",
            "97 block11_sepconv1\n",
            "98 block11_sepconv1_bn\n",
            "99 block11_sepconv2_act\n",
            "100 block11_sepconv2\n",
            "101 block11_sepconv2_bn\n",
            "102 block11_sepconv3_act\n",
            "103 block11_sepconv3\n",
            "104 block11_sepconv3_bn\n",
            "105 add_10\n",
            "106 block12_sepconv1_act\n",
            "107 block12_sepconv1\n",
            "108 block12_sepconv1_bn\n",
            "109 block12_sepconv2_act\n",
            "110 block12_sepconv2\n",
            "111 block12_sepconv2_bn\n",
            "112 block12_sepconv3_act\n",
            "113 block12_sepconv3\n",
            "114 block12_sepconv3_bn\n",
            "115 add_11\n",
            "116 block13_sepconv1_act\n",
            "117 block13_sepconv1\n",
            "118 block13_sepconv1_bn\n",
            "119 block13_sepconv2_act\n",
            "120 block13_sepconv2\n",
            "121 block13_sepconv2_bn\n",
            "122 conv2d_4\n",
            "123 block13_pool\n",
            "124 batch_normalization_4\n",
            "125 add_12\n",
            "126 block14_sepconv1\n",
            "127 block14_sepconv1_bn\n",
            "128 block14_sepconv1_act\n",
            "129 block14_sepconv2\n",
            "130 block14_sepconv2_bn\n",
            "131 block14_sepconv2_act\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "meBUEDGIbe_2",
        "colab_type": "code",
        "outputId": "4da4529e-f1f5-46ce-f56d-1ac24406b054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:36]:\n",
        "   layer.trainable = False\n",
        "    \n",
        "xception_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling3d_1 (UpSampling3 (None, 84, 84, 3)         0         \n",
            "_________________________________________________________________\n",
            "xception (Model)             multiple                  20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 22,969,906\n",
            "Trainable params: 21,808,618\n",
            "Non-trainable params: 1,161,288\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xm9wVgptbu9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the optimizer\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
        "                                            patience=5, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.1, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "xception_model.compile(optimizer=optimizer , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3L2yKR8Hb57T",
        "colab_type": "code",
        "outputId": "bfc46600-7304-413f-c711-6404fe2a9a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 60\n",
        "batch_size = 64\n",
        "xception_history = xception_model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                                                steps_per_epoch=len(x_train) / batch_size, epochs=epochs,\n",
        "                                                validation_data=(x_val, y_val),\n",
        "                                                callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "750/750 [==============================] - 203s 270ms/step - loss: 0.4324 - acc: 0.8665 - val_loss: 0.3587 - val_acc: 0.9637\n",
            "Epoch 2/60\n",
            "750/750 [==============================] - 195s 260ms/step - loss: 0.1116 - acc: 0.9761 - val_loss: 0.0551 - val_acc: 0.9886\n",
            "Epoch 3/60\n",
            "750/750 [==============================] - 194s 259ms/step - loss: 0.0970 - acc: 0.9809 - val_loss: 0.0744 - val_acc: 0.9867\n",
            "Epoch 4/60\n",
            "750/750 [==============================] - 195s 259ms/step - loss: 0.0877 - acc: 0.9847 - val_loss: 0.0922 - val_acc: 0.9868\n",
            "Epoch 5/60\n",
            "750/750 [==============================] - 195s 259ms/step - loss: 0.0796 - acc: 0.9857 - val_loss: 0.2410 - val_acc: 0.9779\n",
            "Epoch 6/60\n",
            "750/750 [==============================] - 194s 259ms/step - loss: 0.0843 - acc: 0.9866 - val_loss: 0.1881 - val_acc: 0.9774\n",
            "Epoch 7/60\n",
            "750/750 [==============================] - 194s 259ms/step - loss: 0.0780 - acc: 0.9874 - val_loss: 0.0614 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 8/60\n",
            "750/750 [==============================] - 195s 260ms/step - loss: 0.0349 - acc: 0.9941 - val_loss: 0.0381 - val_acc: 0.9928\n",
            "Epoch 9/60\n",
            "750/750 [==============================] - 195s 260ms/step - loss: 0.0297 - acc: 0.9945 - val_loss: 0.0353 - val_acc: 0.9936\n",
            "Epoch 10/60\n",
            "750/750 [==============================] - 195s 260ms/step - loss: 0.0266 - acc: 0.9950 - val_loss: 0.0356 - val_acc: 0.9938\n",
            "Epoch 11/60\n",
            "750/750 [==============================] - 195s 260ms/step - loss: 0.0242 - acc: 0.9956 - val_loss: 0.0402 - val_acc: 0.9934\n",
            "Epoch 12/60\n",
            "750/750 [==============================] - 196s 261ms/step - loss: 0.0242 - acc: 0.9960 - val_loss: 0.0425 - val_acc: 0.9933\n",
            "Epoch 13/60\n",
            "750/750 [==============================] - 195s 260ms/step - loss: 0.0230 - acc: 0.9960 - val_loss: 0.0415 - val_acc: 0.9933\n",
            "Epoch 14/60\n",
            "139/750 [====>.........................] - ETA: 2:22 - loss: 0.0236 - acc: 0.9955"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "df9cJqBUcFhD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}